# -*- coding: utf-8 -*-
"""Copy of Deep learning project - with confusion matrix

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sKR5i9helgeLXSFWU_tjg_9QqBlFJOMU
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import os, librosa
import numpy as np
from tqdm import tqdm
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.datasets import fetch_lfw_people
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
import tensorflow_hub as hub
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.optimizers import SGD, RMSprop, Adam
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
np.random.seed(42)
tf.random.set_seed(42)

base_dir = r"/content/drive/MyDrive/genres_original"
def plot_waveform(file_path, genre):
    try:
        # Load the audio file
        y, sr = librosa.load(file_path)
        # Plot the waveform
        plt.figure(figsize=(10, 4))
        librosa.display.waveshow(y, sr=sr)
        plt.title(f'Waveform for {genre} Genre')
        plt.xlabel('Time')
        plt.ylabel('Amplitude')
        plt.show()
    except Exception as e:
        print(f"Error processing file {file_path}: {e}")

# Check if the base directory exists
if not os.path.exists(base_dir):
    print(f"The directory {base_dir} does not exist.")
else:
    print(f"Processing files in {base_dir}...")

# Iterate through each genre folder
for subdir, dirs, files in os.walk(base_dir):
    genre = os.path.basename(subdir)
    if files:
        # Try to plot the waveform for the first file in each genre folder
        file_path = os.path.join(subdir, files[0])
        print(f"Plotting waveform for {file_path}...")
        plot_waveform(file_path, genre)

df1 = pd.read_csv('/content/drive/MyDrive/features_3_sec.csv')
x = df1[["label", "tempo"]]

fig, ax = plt.subplots(figsize=(16, 8));
sns.boxplot(x = "label", y = "tempo", data = x, palette = 'husl');

plt.title('BPM Boxplot for Genres', fontsize = 20)
plt.xticks(fontsize = 14)
plt.yticks(fontsize = 10);
plt.xlabel("Genre", fontsize = 15)
plt.ylabel("BPM", fontsize = 15)
plt.savefig("BPM_Boxplot.png")

df1 = df1.drop(labels='filename',axis=1)

"""First CSV Model"""

features = np.random.rand(100, 20)

# Standardize the features
scaler = StandardScaler()
features_standardized = scaler.fit_transform(features)

# Apply PCA
pca = PCA(n_components=2)
principal_components = pca.fit_transform(features_standardized)


labels = np.random.choice(df1['label'], 100)


# Unique genres in the dataset
unique_genres = np.unique(labels)

# Set up the plot
plt.figure(figsize=(10, 7))

# Plot each genre as a separate set of points
for genre in unique_genres:
    # Indices of songs belonging to the current genre
    idx = np.where(labels == genre)
    # Scatter plot for each genre
    plt.scatter(principal_components[idx, 0], principal_components[idx, 1], label=genre, s=50)

# Labeling the axes based on the principal components
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Music Genres')
plt.legend()
plt.show()

df1.shape

from sklearn.preprocessing import LabelEncoder

class_list = df1.iloc[:, -1]
label = LabelEncoder()
y = label.fit_transform(class_list)

print(y)

print(df1.iloc[:, :-1])

X = scaler.fit_transform(np.array(df1.iloc[:, :-1], dtype = float))

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state=42)

def trainModel(model, epochs, optimizer):
  batch_size = 128
  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')
  return model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=epochs,batch_size=batch_size)

model = Sequential([
    Dense(512, activation='relu', input_shape=(X_train.shape[1], )),
    Dropout(0.2),
    Dense(256, activation='relu'),
    Dropout(0.2),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(10, activation='softmax'),  # Output layer with 10 units for 10 classes
])
model.summary()

history_1 = trainModel(model=model, epochs=40, optimizer='adam')

test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=128)
print("The test loss is:",test_loss)
print("\nThe test accuracy is:",test_acc*100)

def plot_history(history):
    # Plot training & validation accuracy values
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')

    plt.show()

# Assume 'history' is the return value from the 'fit' method
plot_history(history_1)

y_pred = model.predict(X_test)
y_pred = np.argmax(y_pred, axis=1)
conf_mat_1 = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size
sns.heatmap(conf_mat_1, annot=True, fmt='d', cmap='YlGnBu', cbar=False, square=True)

# Customize labels, title, and axis ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(rotation=45)
plt.tight_layout()

# Show plot
plt.show()

"""2nd Model"""

from keras.optimizers import Adam
from keras.callbacks import EarlyStopping

def trainModel2(model, epochs, optimizer):
  batch_size = 256  # Increase batch size
  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')

  # Add early stopping
  early_stopping = EarlyStopping(monitor='val_loss', patience=3)

  return model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])

model2 = Sequential([
    Dense(512, activation='relu', input_shape=(X_train.shape[1], )),
    Dropout(0.3),  # Increase dropout rate
    Dense(256, activation='relu'),
    Dropout(0.3),  # Increase dropout rate
    Dense(128, activation='relu'),
    Dropout(0.3),  # Increase dropout rate
    Dense(64, activation='relu'),
    Dropout(0.3),  # Increase dropout rate
    Dense(10, activation='softmax'),
])

# Use Adam optimizer with a smaller learning rate
optimizer = Adam(learning_rate=0.0001)

model2.summary()

history_2 = trainModel2(model=model2, epochs=200, optimizer=optimizer)

test_loss2, test_acc2 = model2.evaluate(X_test, y_test, batch_size=128)
print("The test loss is:",test_loss2)
print("\nThe test accuracy is:",test_acc2*100)

def plot_history(history):
    # Plot training & validation accuracy values
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')

    plt.show()

plot_history(history_2)

y_pred = model.predict(X_test)
y_pred = np.argmax(y_pred, axis=1)
conf_mat_1 = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size
sns.heatmap(conf_mat_1, annot=True, fmt='d', cmap='YlGnBu', cbar=False, square=True)

# Customize labels, title, and axis ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(rotation=45)
plt.tight_layout()

# Show plot
plt.show()

"""CNN model"""

import os
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from skimage.transform import resize
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import GlobalAveragePooling2D

def audio_file_to_spectrogram(file_path, target_shape=(128, 128)):
    try:
        y, sr = librosa.load(file_path, sr=None)  # Load file with its original sample rate
        # Use keyword arguments for melspectrogram
        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512)
        S_dB = librosa.power_to_db(S, ref=np.max)
        # Resize spectrogram to target shape
        S_resized = resize(S_dB, target_shape, mode='constant', anti_aliasing=True)
        return S_resized[:, :, np.newaxis]  # Add channel dimension
    except Exception as e:
        print(f"Error processing file {file_path}: {str(e)}")
        return None

import random
def load_data_sample(base_dir, sample_size=100, target_shape=(128, 128)):
    X, y = [], []
    genre_paths = [os.path.join(base_dir, genre) for genre in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, genre))]

    for genre_path in genre_paths:
        files = [f for f in os.listdir(genre_path) if f.endswith('.wav')]
        sampled_files = random.sample(files, min(len(files), sample_size))

        for file in sampled_files:
            file_path = os.path.join(genre_path, file)
            spectrogram = audio_file_to_spectrogram(file_path, target_shape)
            if spectrogram is not None:
                X.append(spectrogram)
                y.append(os.path.basename(genre_path))

    return np.array(X), np.array(y)

def prepare_labels(y):
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    return to_categorical(y_encoded)

def split_data(X, y, test_size=0.2):
    return train_test_split(X, y, test_size=test_size, random_state=42)

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Encode genre labels
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(df1['label'])  # 'label' is the column with genre labels
y = to_categorical(encoded_labels)

def resnet(input):
    x11 = Conv2D(64, (1, 1), padding='same', strides=1)(input)
    x12 = Activation('relu')(x11)
    x13 = Concatenate()([x12, input])
    x14 = Conv2D(64, (3, 3), padding='same', strides=1)(x13)
    x15 = Activation('relu')(x14)
    x16 = Concatenate()([x15, input])
    x17 = Conv2D(64, (1, 1), padding='same', strides=1)(x16)
    x18 = Activation('relu')(x17)
    x19 = Concatenate()([x18, input])
    x20 = Conv2D(64, (3, 3), padding='same', strides=1)(x19)
    x21 = Activation('relu')(x20)
    x22 = Concatenate()([x21, input])
    x23 = Conv2D(64, (3, 3), padding='same', strides=1)(x22)
    x24 = Activation('relu')(x23)
    x25 = Conv2D(64, (3, 3), padding='same', strides=1)(input)
    x26 = Activation('relu')(x25)
    x27 = Concatenate()([x26, input])
    x28 = Conv2D(64, (1, 1), padding='same', strides=1)(x27)
    x29 = Activation('relu')(x28)
    x30 = Concatenate()([x29, input])
    x31 = Conv2D(64, (3, 3), padding='same', strides=1)(x30)
    x32 = Activation('relu')(x31)
    x33 = Concatenate()([x32, input])
    x34 = Conv2D(64, (1, 1), padding='same', strides=1)(x33)
    x35 = Activation('relu')(x34)
    x36 = Concatenate()([x35, input, x24])
    x37 = MaxPooling2D(pool_size=2)(x36)
    return x37

def create_cnn_model(input_shape, num_classes):
    inputs = Input(input_shape)
    x08 = Conv2D(64, (1, 1), padding='same', strides=1)(inputs)
    x09 = Activation('relu')(x08)
    x10 = resnet(inputs)
    x11 = resnet(x10)
    x12 = resnet(x11)
    x13 = resnet(x12)
    x14 = resnet(x13)
    x15 = resnet(x14)
    x16 = resnet(x15)
    x = Flatten(name='flatten')(x16)
    x = Dense(256, activation='relu', name='fc1')(x)
    x = Dense(256, activation='relu', name='fc2')(x)
    x = Dense(num_classes, activation='softmax', name='predictions')(x)
    model = Model(inputs, x)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

base_dir = '/content/drive/MyDrive/genres_original'
X, y = load_data_sample(base_dir)
y_categorical = prepare_labels(y)
X_train, X_test, y_train, y_test = split_data(X, y_categorical)

#X = np.squeeze(X, axis=-1)  # This removes the last dimension if it is 1
print("New shape of training data:", X.shape)

#X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)
print("Shape of training data:", X_train.shape)
print("Shape of one sample:", X_train[0].shape)

model = create_cnn_model((128, 128, 1), y_train.shape[1])
model.summary()

history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print(f'Test accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}')

# Visualization of training history
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper left')

plt.show()

y_pred = model.predict(X_test)
y_pred = np.argmax(y_pred, axis=1)
y_test = np.argmax(y_test, axis=1)
conf_mat_1 = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size
sns.heatmap(conf_mat_1, annot=True, fmt='d', cmap='YlGnBu', cbar=False, square=True)

# Customize labels, title, and axis ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(rotation=45)
plt.tight_layout()

# Show plot
plt.show()